# MD5 filesystem tools
Harness the power of MD5 checksums for your filesystem with our toolkit of MD5 filesystem tools designed for managing and analyzing file integrity across nested directories. Features include recursive checksum file creation, duplicate file detection based on checksum comparison, and automated duplicate removal using checksum validation.

## generate_checksums_recursively.sh
This script is designed to recursively find all directories within a specified root directory, calculate the number of files in each directory (excluding subdirectories and any 'checksums.md5' files), and generate a 'checksums.md5' file containing the MD5 checksums for each file within the directory. It also provides feedback on its progress and the results of its operations.

### Usage
This command will process the 'Photos' directory, showing the progress and results for each subdirectory found:
```
./generate_checksums_recursively.sh ~/Photos
```
## find_duplicates.sh
This script is designed to identify and list duplicate files based on their MD5 checksums. It requires a file named **checksums.md5** (generated by **generate_checksums_recursively.sh** or simply by **md5sum**) that contains a list of MD5 checksums and their corresponding files. The script will process this checksum file and group the files by their checksums to identify duplicates.

### Usage
To check for duplicates using a file checksums.md5 in the 'Photos' directory:
```
md5sum ~/Photos/* > checksums.md5
./find_duplicates.sh ~/Photos
```
Example output:
```
26ab0db90d72e28ad0ba1e22ee510510:
/home/user/Photos/Toronto2024.jpg
/home/user/Photos/Toronto2024 (1).jpg

b026324c6904b2a9cb4b88d6d61c81d1:
/home/user/Photos/Paris2023.jpg
/home/user/Photos/Paris2023 (1).jpg
```

## remove_duplicates.sh
This script is designed to identify and remove duplicate files within a specified directory, keeping only the file with the shortest name in each set of duplicates. It utilizes a **checksums.md5** file (generated by **generate_checksums_recursively.sh** or simply by **md5sum**), which should contain the MD5 hashes of the files in the directory, to identify duplicates.

### Usage
To remove duplicates using a file checksums.md5 in the 'Photos' directory:
```
md5sum ~/Photos/* > checksums.md5
./remove_duplicates.sh ~/Photos
```
Example output:
```
The file with the shortest name will be preserved:
/home/user/Photos/Toronto2024.jpg
Removing: /home/user/Photos/Toronto2024 (1).jpg

The file with the shortest name will be preserved:
/home/user/Photos/Paris2023.jpg
/home/user/Photos/Paris2023 (1).jpg
```

